# Final Week: Model Weight Obtained and UI Development

During the previous weeks of the project, we made progress in training the model, monitoring loss values, and analyzing the model's learning progress. In the final week, our primary focus is on the practical application of the trained model. We have obtained the final weights of the model, and now we shift our attention to building a user interface (UI) that allows users to interact with the model effectively. The UI will include functionalities such as image upload, visual display of segmentation, patch extraction, classification, and explanations. Although the UI is currently developed in local environment, it is easy to migrate to cloud and potentially used by clinics or diagnostic centres. This document provides an overview of our progress and outlines the tasks accomplished during the final week.

### 1. Model Weight Obtained:
   - After completing the model training and fine-tuning processes, we successfully obtained the final weights of the model. These weights represent the learned parameters that capture the model's knowledge and ability to detect objects accurately.

### 2. UI Front-end Interface Development:
   - In the final week, we begin developing a user interface (UI) to provide a user-friendly experience for interacting with the model. The UI will enable users to perform various tasks related to object detection, segmentation, patch extraction, classification, and explanations. The UI front-end is written in Javascript using React environment utilising MUI packages.

   a. Image Upload:
      - Implement functionality to allow users to upload images for analysis and detection. The image uploaded will be saved on local device.

   b. Visual Display of Segmentation:
      - Integrate visualization capabilities to display the segmentation results generated by the model. This will allow users to observe the boundaries and masks of detected objects. The front-end client will receive the image and its classification after processing by the back-end server, and it is displayed with progress bars that track the progress of segmentation & classification.

   c. Patch Extraction:
      - Develop functionality to extract patches from the segmented regions. This will enable users to focus on specific regions of interest and perform further analysis or classification.

   d. Classification and Explanation:
      - Implement classification capabilities to predict the class labels of the extracted patches.
      - Integrate an explanation mechanism that provides insights into the model's decision-making process.

### 3. UI Front-end Interface Development:
   - The back-end server is written by javascript to execute the Python code for segmentation/classification with existing weight and return a segmented image, a patch of tumour region and the classification to the front-end client.

